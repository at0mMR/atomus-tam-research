{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atomus TAM Research - MVP Demo\n",
    "\n",
    "This notebook demonstrates the complete Atomus TAM Research workflow for identifying and scoring defense contractors.\n",
    "\n",
    "## Workflow Overview:\n",
    "1. **HigherGov Analysis** - Verify defense contractor status\n",
    "2. **OpenAI Research** - Conduct AI-powered company research\n",
    "3. **Scoring Engine** - Calculate weighted scores and tier classification\n",
    "4. **HubSpot Sync** - Update CRM with results\n",
    "\n",
    "## Test Dataset:\n",
    "We'll process the 13 defense contractor companies through the complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our modules\n",
    "from api_integrations import (\n",
    "    create_hubspot_client,\n",
    "    create_openai_client, \n",
    "    create_highergov_client\n",
    ")\n",
    "from utils import get_logger, get_performance_tracker\n",
    "from scoring_engine import AtomScoringEngine\n",
    "from data_processing import AtomDataProcessor\n",
    "\n",
    "print(\"ğŸš€ Atomus TAM Research MVP Demo\")\n",
    "print(\"=\" * 40)\n",
    "print(\"âœ… All modules imported successfully\")\n",
    "print(f\"ğŸ“ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ System Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize system components\n",
    "logger = get_logger()\n",
    "tracker = get_performance_tracker()\n",
    "\n",
    "print(\"ğŸ”§ Initializing system components...\")\n",
    "\n",
    "# Initialize API clients\n",
    "hubspot_client = create_hubspot_client()\n",
    "openai_client = create_openai_client()\n",
    "highergov_client = create_highergov_client()\n",
    "\n",
    "# Initialize processing engines\n",
    "scoring_engine = AtomScoringEngine()\n",
    "data_processor = AtomDataProcessor()\n",
    "\n",
    "print(\"âœ… All components initialized\")\n",
    "\n",
    "# Test API connections\n",
    "print(\"\\nğŸ”— Testing API connections...\")\n",
    "apis_status = {\n",
    "    'HubSpot': hubspot_client.test_connection(),\n",
    "    'OpenAI': openai_client.test_connection(),\n",
    "    'HigherGov': highergov_client.test_connection()\n",
    "}\n",
    "\n",
    "for api_name, status in apis_status.items():\n",
    "    emoji = \"âœ…\" if status.get('status') == 'connected' else \"âŒ\"\n",
    "    print(f\"   {emoji} {api_name}: {status.get('status', 'unknown')}\")\n",
    "\n",
    "all_connected = all(status.get('status') == 'connected' for status in apis_status.values())\n",
    "print(f\"\\n{'ğŸŸ¢' if all_connected else 'ğŸ”´'} System Status: {'Ready' if all_connected else 'API Issues Detected'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 13 test companies\n",
    "print(\"ğŸ“‹ Loading test dataset...\")\n",
    "\n",
    "test_companies_data = data_processor.load_prospect_database()\n",
    "df_companies = pd.DataFrame(test_companies_data)\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_companies)} companies\")\n",
    "print(f\"ğŸ“Š Columns: {list(df_companies.columns)}\")\n",
    "\n",
    "# Display the test companies\n",
    "print(\"\\nğŸ¢ Test Companies:\")\n",
    "display(df_companies)\n",
    "\n",
    "# Extract company names for processing\n",
    "company_names = df_companies['name'].tolist()\n",
    "print(f\"\\nğŸ¯ Companies to process: {company_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ MVP Workflow Execution\n",
    "\n",
    "Process each company through the complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main workflow function\n",
    "def process_company_workflow(company_name, company_data=None):\n",
    "    \"\"\"\n",
    "    Process a single company through the complete Atomus workflow\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¢ Processing: {company_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    tracker.start_timing(f\"company_workflow_{company_name}\")\n",
    "    \n",
    "    results = {\n",
    "        'company_name': company_name,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'workflow_steps': {},\n",
    "        'final_results': {}\n",
    "    }\n",
    "    \n",
    "    # Step 1: HigherGov Defense Contractor Analysis\n",
    "    print(\"ğŸ›¡ï¸ Step 1: Defense Contractor Analysis...\")\n",
    "    try:\n",
    "        tracker.start_timing(\"highergov_analysis\")\n",
    "        defense_data = highergov_client.analyze_defense_contractor_status(company_name)\n",
    "        tracker.end_timing(\"highergov_analysis\", f\"Analyzed {company_name}\")\n",
    "        \n",
    "        results['workflow_steps']['defense_analysis'] = {\n",
    "            'status': 'success',\n",
    "            'defense_score': defense_data['defense_contractor_score'],\n",
    "            'contract_count': defense_data['contract_analysis']['defense_contracts'],\n",
    "            'total_contracts': defense_data['contract_analysis']['total_contracts'],\n",
    "            'identifiers_found': len(defense_data['identifiers'])\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Defense Score: {defense_data['defense_contractor_score']}/100\")\n",
    "        print(f\"   ğŸ“‹ Defense Contracts: {defense_data['contract_analysis']['defense_contracts']}\")\n",
    "        print(f\"   ğŸ¢ Total Contracts: {defense_data['contract_analysis']['total_contracts']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results['workflow_steps']['defense_analysis'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "    \n",
    "    # Step 2: OpenAI Research\n",
    "    print(\"\\nğŸ¤– Step 2: AI-Powered Research...\")\n",
    "    try:\n",
    "        tracker.start_timing(\"openai_research\")\n",
    "        research_data = openai_client.conduct_research(\n",
    "            company_name=company_name,\n",
    "            research_type=\"basic_research\",\n",
    "            research_category=\"defense_contractor_analysis\"\n",
    "        )\n",
    "        tracker.end_timing(\"openai_research\", f\"Researched {company_name}\")\n",
    "        \n",
    "        results['workflow_steps']['ai_research'] = {\n",
    "            'status': 'success',\n",
    "            'tokens_used': research_data['metadata']['tokens_used'],\n",
    "            'content_length': len(research_data['content']),\n",
    "            'research_summary': research_data['content'][:300] + \"...\" if len(research_data['content']) > 300 else research_data['content']\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Research completed: {research_data['metadata']['tokens_used']} tokens\")\n",
    "        print(f\"   ğŸ“„ Content length: {len(research_data['content'])} characters\")\n",
    "        print(f\"   ğŸ“ Preview: {research_data['content'][:150]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results['workflow_steps']['ai_research'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        research_data = None\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "    \n",
    "    # Step 3: Scoring Engine\n",
    "    print(\"\\nğŸ§® Step 3: Scoring Calculation...\")\n",
    "    try:\n",
    "        tracker.start_timing(\"scoring_calculation\")\n",
    "        \n",
    "        # Prepare company data for scoring\n",
    "        scoring_input = {\n",
    "            'name': company_name,\n",
    "            'description': research_data['content'] if research_data else f\"Defense contractor: {company_name}\",\n",
    "            'defense_contractor_score': results['workflow_steps']['defense_analysis'].get('defense_score', 0) if results['workflow_steps']['defense_analysis']['status'] == 'success' else 0\n",
    "        }\n",
    "        \n",
    "        # Add company data if available\n",
    "        if company_data:\n",
    "            scoring_input.update(company_data)\n",
    "        \n",
    "        scoring_result = scoring_engine.calculate_company_score(scoring_input)\n",
    "        tracker.end_timing(\"scoring_calculation\", f\"Scored {company_name}\")\n",
    "        \n",
    "        results['workflow_steps']['scoring'] = {\n",
    "            'status': 'success',\n",
    "            'total_score': scoring_result['total_score'],\n",
    "            'tier_classification': scoring_result['tier_classification'],\n",
    "            'component_scores': scoring_result['component_scores'],\n",
    "            'keywords_found': scoring_result['keywords_found']\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Total Score: {scoring_result['total_score']:.1f}/100\")\n",
    "        print(f\"   ğŸ† Tier: {scoring_result['tier_classification']}\")\n",
    "        print(f\"   ğŸ“Š Component Scores: {scoring_result['component_scores']}\")\n",
    "        \n",
    "        # Show keywords found\n",
    "        keywords_summary = []\n",
    "        for category, keywords in scoring_result['keywords_found'].items():\n",
    "            if keywords:\n",
    "                keywords_summary.append(f\"{category}: {len(keywords)}\")\n",
    "        \n",
    "        if keywords_summary:\n",
    "            print(f\"   ğŸ”¤ Keywords: {', '.join(keywords_summary)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results['workflow_steps']['scoring'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        scoring_result = None\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "    \n",
    "    # Step 4: HubSpot Sync\n",
    "    print(\"\\nğŸ“Š Step 4: HubSpot CRM Sync...\")\n",
    "    try:\n",
    "        tracker.start_timing(\"hubspot_sync\")\n",
    "        \n",
    "        # Prepare HubSpot data\n",
    "        hubspot_data = {\n",
    "            'name': company_name,\n",
    "            'atomus_score': scoring_result['total_score'] if scoring_result else 0,\n",
    "            'defense_contract_score': results['workflow_steps']['defense_analysis'].get('defense_score', 0) if results['workflow_steps']['defense_analysis']['status'] == 'success' else 0,\n",
    "            'tier_classification': scoring_result['tier_classification'] if scoring_result else 'unscored',\n",
    "            'last_research_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "            'research_summary': results['workflow_steps']['ai_research'].get('research_summary', 'Research failed') if results['workflow_steps']['ai_research']['status'] == 'success' else 'Research failed'\n",
    "        }\n",
    "        \n",
    "        # Check if company exists in HubSpot\n",
    "        existing_companies = hubspot_client.search_companies({'name': company_name})\n",
    "        \n",
    "        if existing_companies:\n",
    "            # Update existing company\n",
    "            company_id = existing_companies[0]['id']\n",
    "            updated_company = hubspot_client.update_company(company_id, hubspot_data)\n",
    "            \n",
    "            results['workflow_steps']['hubspot_sync'] = {\n",
    "                'status': 'updated',\n",
    "                'company_id': company_id,\n",
    "                'action': 'updated existing record'\n",
    "            }\n",
    "            print(f\"   âœ… Updated existing HubSpot record: {company_id}\")\n",
    "            \n",
    "        else:\n",
    "            # Create new company\n",
    "            new_company = hubspot_client.create_company(hubspot_data)\n",
    "            \n",
    "            results['workflow_steps']['hubspot_sync'] = {\n",
    "                'status': 'created',\n",
    "                'company_id': new_company['id'],\n",
    "                'action': 'created new record'\n",
    "            }\n",
    "            print(f\"   âœ… Created new HubSpot record: {new_company['id']}\")\n",
    "        \n",
    "        tracker.end_timing(\"hubspot_sync\", f\"Synced {company_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results['workflow_steps']['hubspot_sync'] = {\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "    \n",
    "    # Calculate final results\n",
    "    successful_steps = sum(1 for step in results['workflow_steps'].values() \n",
    "                          if step['status'] in ['success', 'created', 'updated'])\n",
    "    total_steps = len(results['workflow_steps'])\n",
    "    \n",
    "    results['final_results'] = {\n",
    "        'success_rate': f\"{successful_steps}/{total_steps}\",\n",
    "        'overall_status': 'success' if successful_steps == total_steps else 'partial_success' if successful_steps > 0 else 'failed',\n",
    "        'atomus_score': scoring_result['total_score'] if scoring_result else 0,\n",
    "        'tier': scoring_result['tier_classification'] if scoring_result else 'unscored'\n",
    "    }\n",
    "    \n",
    "    tracker.end_timing(f\"company_workflow_{company_name}\", f\"Completed workflow\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nğŸ“‹ WORKFLOW SUMMARY:\")\n",
    "    status_emoji = \"âœ…\" if results['final_results']['overall_status'] == 'success' else \"âš ï¸\" if results['final_results']['overall_status'] == 'partial_success' else \"âŒ\"\n",
    "    print(f\"   {status_emoji} Overall Status: {results['final_results']['overall_status']}\")\n",
    "    print(f\"   ğŸ“ˆ Success Rate: {results['final_results']['success_rate']}\")\n",
    "    print(f\"   ğŸ¯ Final Score: {results['final_results']['atomus_score']:.1f}\")\n",
    "    print(f\"   ğŸ† Tier: {results['final_results']['tier']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… Workflow function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Process Sample Companies\n",
    "\n",
    "Let's start with 3 companies to test the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a subset of companies first (3 companies for initial testing)\n",
    "sample_companies = company_names[:3]  # Firestorm, Firehawk, Overland AI\n",
    "\n",
    "print(f\"ğŸ¯ Processing {len(sample_companies)} sample companies...\")\n",
    "print(f\"Companies: {sample_companies}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "workflow_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, company_name in enumerate(sample_companies, 1):\n",
    "    print(f\"\\nğŸš€ [{i}/{len(sample_companies)}] Starting workflow for {company_name}...\")\n",
    "    \n",
    "    # Get company data from our dataset if available\n",
    "    company_row = df_companies[df_companies['name'] == company_name]\n",
    "    company_data = company_row.iloc[0].to_dict() if not company_row.empty else None\n",
    "    \n",
    "    try:\n",
    "        result = process_company_workflow(company_name, company_data)\n",
    "        workflow_results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Workflow failed for {company_name}: {str(e)}\")\n",
    "        workflow_results.append({\n",
    "            'company_name': company_name,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'error': str(e),\n",
    "            'final_results': {'overall_status': 'failed'}\n",
    "        })\n",
    "    \n",
    "    # Add delay between companies to respect API limits\n",
    "    if i < len(sample_companies):\n",
    "        print(\"â³ Waiting 2 seconds before next company...\")\n",
    "        time.sleep(2)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nâ±ï¸ Total processing time: {total_time:.1f} seconds\")\n",
    "print(f\"ğŸ“Š Average time per company: {total_time/len(sample_companies):.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "print(\"ğŸ“Š RESULTS ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if workflow_results:\n",
    "    # Create results dataframe\n",
    "    results_summary = []\n",
    "    \n",
    "    for result in workflow_results:\n",
    "        company_name = result['company_name']\n",
    "        final_results = result.get('final_results', {})\n",
    "        \n",
    "        summary = {\n",
    "            'Company': company_name,\n",
    "            'Status': final_results.get('overall_status', 'unknown'),\n",
    "            'Score': final_results.get('atomus_score', 0),\n",
    "            'Tier': final_results.get('tier', 'unknown'),\n",
    "            'Success_Rate': final_results.get('success_rate', '0/4')\n",
    "        }\n",
    "        \n",
    "        # Add step-by-step status\n",
    "        workflow_steps = result.get('workflow_steps', {})\n",
    "        summary['Defense_Analysis'] = workflow_steps.get('defense_analysis', {}).get('status', 'unknown')\n",
    "        summary['AI_Research'] = workflow_steps.get('ai_research', {}).get('status', 'unknown')\n",
    "        summary['Scoring'] = workflow_steps.get('scoring', {}).get('status', 'unknown')\n",
    "        summary['HubSpot_Sync'] = workflow_steps.get('hubspot_sync', {}).get('status', 'unknown')\n",
    "        \n",
    "        results_summary.append(summary)\n",
    "    \n",
    "    # Display results table\n",
    "    df_results = pd.DataFrame(results_summary)\n",
    "    print(\"ğŸ† Workflow Results Summary:\")\n",
    "    display(df_results)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    successful_companies = len([r for r in workflow_results if r.get('final_results', {}).get('overall_status') == 'success'])\n",
    "    partial_success = len([r for r in workflow_results if r.get('final_results', {}).get('overall_status') == 'partial_success'])\n",
    "    failed_companies = len([r for r in workflow_results if r.get('final_results', {}).get('overall_status') == 'failed'])\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Overall Statistics:\")\n",
    "    print(f\"   âœ… Fully Successful: {successful_companies}/{len(workflow_results)}\")\n",
    "    print(f\"   âš ï¸ Partial Success: {partial_success}/{len(workflow_results)}\")\n",
    "    print(f\"   âŒ Failed: {failed_companies}/{len(workflow_results)}\")\n",
    "    \n",
    "    # Score distribution\n",
    "    scores = [r.get('final_results', {}).get('atomus_score', 0) for r in workflow_results if isinstance(r.get('final_results', {}).get('atomus_score'), (int, float))]\n",
    "    if scores:\n",
    "        print(f\"\\nğŸ¯ Score Statistics:\")\n",
    "        print(f\"   Average Score: {sum(scores)/len(scores):.1f}\")\n",
    "        print(f\"   Highest Score: {max(scores):.1f}\")\n",
    "        print(f\"   Lowest Score: {min(scores):.1f}\")\n",
    "    \n",
    "    # Tier distribution\n",
    "    tiers = [r.get('final_results', {}).get('tier', 'unknown') for r in workflow_results]\n",
    "    tier_counts = {}\n",
    "    for tier in tiers:\n",
    "        tier_counts[tier] = tier_counts.get(tier, 0) + 1\n",
    "    \n",
    "    print(f\"\\nğŸ† Tier Distribution:\")\n",
    "    for tier, count in tier_counts.items():\n",
    "        print(f\"   {tier}: {count} companies\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis\n",
    "print(\"ğŸ“ˆ PERFORMANCE METRICS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# API Usage Statistics\n",
    "print(\"ğŸ”µ HubSpot API Usage:\")\n",
    "hubspot_client.log_stats_summary()\n",
    "\n",
    "print(\"\\nğŸ¤– OpenAI API Usage:\")\n",
    "openai_client.log_stats_summary()\n",
    "\n",
    "print(\"\\nğŸ›¡ï¸ HigherGov API Usage:\")\n",
    "highergov_client.log_stats_summary()\n",
    "\n",
    "# Timing analysis\n",
    "print(\"\\nâ±ï¸ Timing Analysis:\")\n",
    "timing_results = tracker.get_timing_summary()\n",
    "if timing_results:\n",
    "    for operation, times in timing_results.items():\n",
    "        if times:\n",
    "            avg_time = sum(times) / len(times)\n",
    "            total_time = sum(times)\n",
    "            print(f\"   {operation}: {avg_time:.2f}s avg, {total_time:.2f}s total ({len(times)} calls)\")\nelse:\n",
    "    print(\"   No timing data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save workflow results\n",
    "print(\"ğŸ’¾ SAVING RESULTS\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "try:\n",
    "    # Create results directory\n",
    "    results_dir = Path(\"../data/research_results\")\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save detailed results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    detailed_results_file = results_dir / f\"mvp_demo_detailed_{timestamp}.json\"\n",
    "    \n",
    "    with open(detailed_results_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(workflow_results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"âœ… Detailed results saved: {detailed_results_file}\")\n",
    "    \n",
    "    # Save summary CSV\n",
    "    if 'df_results' in locals():\n",
    "        summary_csv_file = results_dir / f\"mvp_demo_summary_{timestamp}.csv\"\n",
    "        df_results.to_csv(summary_csv_file, index=False)\n",
    "        print(f\"âœ… Summary CSV saved: {summary_csv_file}\")\n",
    "    \n",
    "    # Save performance metrics\n",
    "    performance_file = results_dir / f\"mvp_demo_performance_{timestamp}.json\"\n",
    "    performance_data = {\n",
    "        'timing_results': timing_results,\n",
    "        'api_stats': {\n",
    "            'hubspot': hubspot_client.get_stats_summary(),\n",
    "            'openai': openai_client.get_stats_summary(),\n",
    "            'highergov': highergov_client.get_stats_summary()\n",
    "        },\n",
    "        'processed_companies': len(workflow_results),\n",
    "        'total_processing_time': total_time if 'total_time' in locals() else 0\n",
    "    }\n",
    "    \n",
    "    with open(performance_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(performance_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"âœ… Performance data saved: {performance_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error saving results: {str(e)}\")\n",
    "\n",
    "print(f\"\\nğŸ“ All results saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Next Steps\n",
    "\n",
    "Based on the results above, you can:\n",
    "\n",
    "1. **Process More Companies**: Change `sample_companies` to include more companies from the dataset\n",
    "2. **Debug Issues**: Use the debugging tools notebook to investigate any failures\n",
    "3. **Adjust Configuration**: Modify scoring weights or research prompts based on results\n",
    "4. **Scale Up**: Process all 13 companies once you're satisfied with the results\n",
    "\n",
    "## ğŸ”§ Configuration Adjustments\n",
    "\n",
    "Use this section to test configuration changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration testing area\n",
    "print(\"ğŸ”§ CONFIGURATION TESTING\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Example: Test different scoring weights\n",
    "current_config = scoring_engine.get_config_summary()\n",
    "print(f\"ğŸ“ Current scoring weights: {current_config['weights']}\")\n",
    "print(f\"ğŸ¯ Current tier thresholds: {current_config['tier_thresholds']}\")\n",
    "\n",
    "# You can modify and test new configurations here\n",
    "print(\"\\nğŸ’¡ Use this section to test configuration changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… MVP Demo Complete\n",
    "\n",
    "The MVP demo has successfully demonstrated:\n",
    "\n",
    "- âœ… Complete API integration workflow\n",
    "- âœ… Defense contractor analysis via HigherGov\n",
    "- âœ… AI-powered research via OpenAI\n",
    "- âœ… Weighted scoring and tier classification\n",
    "- âœ… HubSpot CRM synchronization\n",
    "- âœ… Performance monitoring and error handling\n",
    "- âœ… Results export and analysis\n",
    "\n",
    "**Ready for production scaling!** ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}