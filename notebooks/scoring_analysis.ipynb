{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atomus TAM Research - Scoring Analysis\n",
    "\n",
    "This notebook provides tools for analyzing and optimizing the Atomus scoring algorithm.\n",
    "\n",
    "## Features:\n",
    "- Interactive scoring analysis\n",
    "- Weight optimization\n",
    "- Keyword effectiveness analysis\n",
    "- Tier distribution analysis\n",
    "- Comparative scoring scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our modules\n",
    "from scoring_engine import AtomScoringEngine\n",
    "from data_processing import AtomDataProcessor\n",
    "from utils import get_logger\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Atomus Scoring Analysis\")\n",
    "print(\"=\" * 30)\n",
    "print(\"‚úÖ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Initialize Scoring Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "logger = get_logger()\n",
    "scoring_engine = AtomScoringEngine()\n",
    "data_processor = AtomDataProcessor()\n",
    "\n",
    "print(\"üîß Initializing scoring engine...\")\n",
    "\n",
    "# Get current configuration\n",
    "config = scoring_engine.get_config_summary()\n",
    "\n",
    "print(f\"\\nüìè Current Configuration:\")\n",
    "print(f\"   Scoring Weights: {config['weights']}\")\n",
    "print(f\"   Tier Thresholds: {config['tier_thresholds']}\")\n",
    "print(f\"   Keyword Categories: {len(config['keywords'])} categories\")\n",
    "\n",
    "# Show keyword details\n",
    "print(f\"\\nüî§ Keyword Distribution:\")\n",
    "for category, keywords in config['keywords'].items():\n",
    "    print(f\"   {category}: {len(keywords)} keywords\")\n",
    "    print(f\"      Sample: {keywords[:3] if len(keywords) >= 3 else keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test companies\n",
    "print(\"üìã Loading test dataset...\")\n",
    "\n",
    "test_companies = data_processor.load_prospect_database()\n",
    "df_companies = pd.DataFrame(test_companies)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df_companies)} companies\")\n",
    "print(f\"üìä Columns: {list(df_companies.columns)}\")\n",
    "\n",
    "# Display companies\n",
    "print(\"\\nüè¢ Test Companies:\")\n",
    "display(df_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Interactive Scoring Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all test companies\n",
    "print(\"üßÆ Scoring all test companies...\")\n",
    "\n",
    "scoring_results = []\n",
    "\n",
    "for _, company_row in df_companies.iterrows():\n",
    "    company_data = company_row.to_dict()\n",
    "    \n",
    "    try:\n",
    "        result = scoring_engine.calculate_company_score(company_data)\n",
    "        \n",
    "        # Add company name to result\n",
    "        result['company_name'] = company_data['name']\n",
    "        scoring_results.append(result)\n",
    "        \n",
    "        print(f\"   ‚úÖ {company_data['name']}: {result['total_score']:.1f} ({result['tier_classification']})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå {company_data['name']}: Error - {str(e)}\")\n",
    "\n",
    "print(f\"\\nüìä Successfully scored {len(scoring_results)} companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed results dataframe\n",
    "if scoring_results:\n",
    "    detailed_results = []\n",
    "    \n",
    "    for result in scoring_results:\n",
    "        row = {\n",
    "            'Company': result['company_name'],\n",
    "            'Total_Score': result['total_score'],\n",
    "            'Tier': result['tier_classification']\n",
    "        }\n",
    "        \n",
    "        # Add component scores\n",
    "        for component, score in result['component_scores'].items():\n",
    "            row[f'{component}_Score'] = score\n",
    "        \n",
    "        # Add keyword counts\n",
    "        for category, keywords in result['keywords_found'].items():\n",
    "            row[f'{category}_Keywords'] = len(keywords) if keywords else 0\n",
    "        \n",
    "        detailed_results.append(row)\n",
    "    \n",
    "    df_results = pd.DataFrame(detailed_results)\n",
    "    \n",
    "    print(\"üìä Detailed Scoring Results:\")\n",
    "    display(df_results)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No scoring results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Score Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score distribution visualization\n",
    "if scoring_results:\n",
    "    scores = [r['total_score'] for r in scoring_results]\n",
    "    company_names = [r['company_name'] for r in scoring_results]\n",
    "    tiers = [r['tier_classification'] for r in scoring_results]\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Score distribution histogram\n",
    "    ax1.hist(scores, bins=10, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('Total Score')\n",
    "    ax1.set_ylabel('Number of Companies')\n",
    "    ax1.set_title('Score Distribution')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add tier lines\n",
    "    tier_thresholds = config['tier_thresholds']\n",
    "    for tier, threshold in tier_thresholds.items():\n",
    "        if tier != 'tier_4':  # Skip the lowest threshold\n",
    "            ax1.axvline(threshold, color='red', linestyle='--', alpha=0.5, label=f'{tier}: {threshold}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Company scores bar chart\n",
    "    bars = ax2.bar(range(len(scores)), scores, color='skyblue', edgecolor='black')\n",
    "    ax2.set_xlabel('Companies')\n",
    "    ax2.set_ylabel('Total Score')\n",
    "    ax2.set_title('Individual Company Scores')\n",
    "    ax2.set_xticks(range(len(company_names)))\n",
    "    ax2.set_xticklabels(company_names, rotation=45, ha='right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Color bars by tier\n",
    "    tier_colors = {'tier_1': 'darkgreen', 'tier_2': 'green', 'tier_3': 'orange', 'tier_4': 'red', 'excluded': 'gray'}\n",
    "    for i, (bar, tier) in enumerate(zip(bars, tiers)):\n",
    "        bar.set_color(tier_colors.get(tier, 'skyblue'))\n",
    "    \n",
    "    # 3. Tier distribution pie chart\n",
    "    tier_counts = Counter(tiers)\n",
    "    ax3.pie(tier_counts.values(), labels=tier_counts.keys(), autopct='%1.1f%%', startangle=90)\n",
    "    ax3.set_title('Tier Distribution')\n",
    "    \n",
    "    # 4. Component score comparison\n",
    "    if 'df_results' in locals():\n",
    "        component_cols = [col for col in df_results.columns if col.endswith('_Score') and col != 'Total_Score']\n",
    "        if component_cols:\n",
    "            component_means = df_results[component_cols].mean()\n",
    "            ax4.bar(range(len(component_means)), component_means.values, color='lightcoral', edgecolor='black')\n",
    "            ax4.set_xlabel('Score Components')\n",
    "            ax4.set_ylabel('Average Score')\n",
    "            ax4.set_title('Average Component Scores')\n",
    "            ax4.set_xticks(range(len(component_means)))\n",
    "            ax4.set_xticklabels([col.replace('_Score', '') for col in component_means.index], rotation=45, ha='right')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nüìä Score Statistics:\")\n",
    "    print(f\"   Mean: {np.mean(scores):.2f}\")\n",
    "    print(f\"   Median: {np.median(scores):.2f}\")\n",
    "    print(f\"   Std Dev: {np.std(scores):.2f}\")\n",
    "    print(f\"   Min: {np.min(scores):.2f}\")\n",
    "    print(f\"   Max: {np.max(scores):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Tier Breakdown:\")\n",
    "    for tier, count in tier_counts.items():\n",
    "        percentage = (count / len(tiers)) * 100\n",
    "        print(f\"   {tier}: {count} companies ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî§ Keyword Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword effectiveness analysis\n",
    "print(\"üî§ Keyword Effectiveness Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if scoring_results:\n",
    "    # Collect all keywords found\n",
    "    all_keywords_found = {}\n",
    "    keyword_company_mapping = {}\n",
    "    \n",
    "    for result in scoring_results:\n",
    "        company = result['company_name']\n",
    "        \n",
    "        for category, keywords in result['keywords_found'].items():\n",
    "            if category not in all_keywords_found:\n",
    "                all_keywords_found[category] = []\n",
    "                keyword_company_mapping[category] = {}\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                all_keywords_found[category].append(keyword)\n",
    "                if keyword not in keyword_company_mapping[category]:\n",
    "                    keyword_company_mapping[category][keyword] = []\n",
    "                keyword_company_mapping[category][keyword].append(company)\n",
    "    \n",
    "    # Analyze keyword frequency\n",
    "    print(\"üìà Keyword Frequency Analysis:\")\n",
    "    \n",
    "    for category, keywords in all_keywords_found.items():\n",
    "        if keywords:\n",
    "            keyword_counts = Counter(keywords)\n",
    "            print(f\"\\n   {category.upper()}:\")\n",
    "            for keyword, count in keyword_counts.most_common(5):\n",
    "                companies = keyword_company_mapping[category][keyword]\n",
    "                print(f\"     '{keyword}': {count} companies ({companies})\")\n",
    "        else:\n",
    "            print(f\"\\n   {category.upper()}: No keywords found\")\n",
    "    \n",
    "    # Visualize keyword usage\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (category, keywords) in enumerate(all_keywords_found.items()):\n",
    "        if i < len(axes) and keywords:\n",
    "            keyword_counts = Counter(keywords)\n",
    "            top_keywords = keyword_counts.most_common(5)\n",
    "            \n",
    "            if top_keywords:\n",
    "                words, counts = zip(*top_keywords)\n",
    "                axes[i].bar(range(len(words)), counts, color='lightblue', edgecolor='black')\n",
    "                axes[i].set_title(f'{category.title()} Keywords')\n",
    "                axes[i].set_xticks(range(len(words)))\n",
    "                axes[i].set_xticklabels(words, rotation=45, ha='right')\n",
    "                axes[i].set_ylabel('Frequency')\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(all_keywords_found), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No keyword data to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Weight Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight sensitivity analysis\n",
    "print(\"‚öñÔ∏è Weight Sensitivity Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if scoring_results and len(scoring_results) > 0:\n",
    "    # Test different weight configurations\n",
    "    weight_scenarios = {\n",
    "        'Current': config['weights'],\n",
    "        'Defense Heavy': {\n",
    "            'defense_contract_score': 0.5,\n",
    "            'technology_relevance': 0.2,\n",
    "            'compliance_indicators': 0.2,\n",
    "            'firmographics': 0.1\n",
    "        },\n",
    "        'Tech Heavy': {\n",
    "            'defense_contract_score': 0.2,\n",
    "            'technology_relevance': 0.5,\n",
    "            'compliance_indicators': 0.2,\n",
    "            'firmographics': 0.1\n",
    "        },\n",
    "        'Balanced': {\n",
    "            'defense_contract_score': 0.25,\n",
    "            'technology_relevance': 0.25,\n",
    "            'compliance_indicators': 0.25,\n",
    "            'firmographics': 0.25\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Calculate scores for each scenario\n",
    "    scenario_results = {}\n",
    "    \n",
    "    for scenario_name, weights in weight_scenarios.items():\n",
    "        print(f\"\\nüìä Testing scenario: {scenario_name}\")\n",
    "        print(f\"   Weights: {weights}\")\n",
    "        \n",
    "        scenario_scores = []\n",
    "        \n",
    "        for result in scoring_results:\n",
    "            # Recalculate weighted score\n",
    "            component_scores = result['component_scores']\n",
    "            \n",
    "            weighted_score = sum(\n",
    "                component_scores.get(component, 0) * weight\n",
    "                for component, weight in weights.items()\n",
    "            )\n",
    "            \n",
    "            scenario_scores.append(weighted_score)\n",
    "        \n",
    "        scenario_results[scenario_name] = scenario_scores\n",
    "        \n",
    "        # Print summary stats\n",
    "        print(f\"   Mean score: {np.mean(scenario_scores):.2f}\")\n",
    "        print(f\"   Score range: {np.min(scenario_scores):.2f} - {np.max(scenario_scores):.2f}\")\n",
    "    \n",
    "    # Visualize weight sensitivity\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Box plot of score distributions\n",
    "    scenario_data = [scores for scores in scenario_results.values()]\n",
    "    scenario_names = list(scenario_results.keys())\n",
    "    \n",
    "    ax1.boxplot(scenario_data, labels=scenario_names)\n",
    "    ax1.set_title('Score Distributions by Weight Scenario')\n",
    "    ax1.set_ylabel('Total Score')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Line plot showing score changes for each company\n",
    "    for i, company in enumerate(company_names):\n",
    "        company_scores = [scenario_results[scenario][i] for scenario in scenario_names]\n",
    "        ax2.plot(scenario_names, company_scores, marker='o', label=company, alpha=0.7)\n",
    "    \n",
    "    ax2.set_title('Company Score Changes Across Scenarios')\n",
    "    ax2.set_ylabel('Total Score')\n",
    "    ax2.set_xlabel('Weight Scenario')\n",
    "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show ranking changes\n",
    "    print(f\"\\nüèÜ Ranking Changes Across Scenarios:\")\n",
    "    ranking_df = pd.DataFrame()\n",
    "    \n",
    "    for scenario_name, scores in scenario_results.items():\n",
    "        # Create ranking (1 = highest score)\n",
    "        rankings = pd.Series(scores, index=company_names).rank(ascending=False, method='min')\n",
    "        ranking_df[scenario_name] = rankings\n",
    "    \n",
    "    display(ranking_df.astype(int))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No scoring results available for weight analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Tier Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tier threshold optimization\n",
    "print(\"üéØ Tier Threshold Optimization\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if scoring_results:\n",
    "    scores = [r['total_score'] for r in scoring_results]\n",
    "    current_thresholds = config['tier_thresholds']\n",
    "    \n",
    "    print(f\"Current thresholds: {current_thresholds}\")\n",
    "    \n",
    "    # Analyze current tier distribution\n",
    "    def classify_tier(score, thresholds):\n",
    "        if score >= thresholds['tier_1']:\n",
    "            return 'tier_1'\n",
    "        elif score >= thresholds['tier_2']:\n",
    "            return 'tier_2'\n",
    "        elif score >= thresholds['tier_3']:\n",
    "            return 'tier_3'\n",
    "        elif score >= thresholds['tier_4']:\n",
    "            return 'tier_4'\n",
    "        else:\n",
    "            return 'excluded'\n",
    "    \n",
    "    current_tiers = [classify_tier(score, current_thresholds) for score in scores]\n",
    "    current_distribution = Counter(current_tiers)\n",
    "    \n",
    "    print(f\"\\nüìä Current Distribution:\")\n",
    "    for tier, count in current_distribution.items():\n",
    "        percentage = (count / len(scores)) * 100\n",
    "        print(f\"   {tier}: {count} companies ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Test alternative threshold configurations\n",
    "    alternative_thresholds = {\n",
    "        'More Selective': {'tier_1': 95, 'tier_2': 85, 'tier_3': 70, 'tier_4': 55},\n",
    "        'Less Selective': {'tier_1': 85, 'tier_2': 70, 'tier_3': 55, 'tier_4': 40},\n",
    "        'Even Distribution': {'tier_1': 90, 'tier_2': 75, 'tier_3': 60, 'tier_4': 45}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüîÑ Alternative Threshold Scenarios:\")\n",
    "    \n",
    "    threshold_results = {'Current': current_distribution}\n",
    "    \n",
    "    for scenario_name, thresholds in alternative_thresholds.items():\n",
    "        alt_tiers = [classify_tier(score, thresholds) for score in scores]\n",
    "        alt_distribution = Counter(alt_tiers)\n",
    "        threshold_results[scenario_name] = alt_distribution\n",
    "        \n",
    "        print(f\"\\n   {scenario_name} ({thresholds}):\")\n",
    "        for tier, count in alt_distribution.items():\n",
    "            percentage = (count / len(scores)) * 100\n",
    "            print(f\"     {tier}: {count} companies ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Visualize threshold scenarios\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    tier_order = ['tier_1', 'tier_2', 'tier_3', 'tier_4', 'excluded']\n",
    "    colors = ['darkgreen', 'green', 'orange', 'red', 'gray']\n",
    "    \n",
    "    for i, (scenario_name, distribution) in enumerate(threshold_results.items()):\n",
    "        if i < len(axes):\n",
    "            tier_counts = [distribution.get(tier, 0) for tier in tier_order]\n",
    "            \n",
    "            axes[i].pie(tier_counts, labels=tier_order, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "            axes[i].set_title(f'{scenario_name} Distribution')\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    if len(threshold_results) < len(axes):\n",
    "        for i in range(len(threshold_results), len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No scoring results available for tier analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Company Deep Dive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive company analysis\n",
    "print(\"üî¨ Company Deep Dive Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "def analyze_company_scoring(company_name):\n",
    "    \"\"\"Detailed analysis of a specific company's scoring\"\"\"\n",
    "    \n",
    "    # Find the company result\n",
    "    company_result = None\n",
    "    for result in scoring_results:\n",
    "        if result['company_name'] == company_name:\n",
    "            company_result = result\n",
    "            break\n",
    "    \n",
    "    if not company_result:\n",
    "        print(f\"‚ùå Company '{company_name}' not found in results\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüè¢ DEEP DIVE: {company_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"üéØ Total Score: {company_result['total_score']:.2f}\")\n",
    "    print(f\"üèÜ Tier: {company_result['tier_classification']}\")\n",
    "    \n",
    "    # Component breakdown\n",
    "    print(f\"\\nüìä Component Scores:\")\n",
    "    for component, score in company_result['component_scores'].items():\n",
    "        weight = config['weights'].get(component, 0)\n",
    "        weighted_contribution = score * weight\n",
    "        print(f\"   {component}: {score:.2f} (weight: {weight}) = {weighted_contribution:.2f}\")\n",
    "    \n",
    "    # Keywords found\n",
    "    print(f\"\\nüî§ Keywords Found:\")\n",
    "    total_keywords = 0\n",
    "    for category, keywords in company_result['keywords_found'].items():\n",
    "        if keywords:\n",
    "            print(f\"   {category}: {keywords}\")\n",
    "            total_keywords += len(keywords)\n",
    "        else:\n",
    "            print(f\"   {category}: None\")\n",
    "    \n",
    "    print(f\"\\nüìà Total Keywords Found: {total_keywords}\")\n",
    "    \n",
    "    # Calculation details\n",
    "    if 'calculation_details' in company_result:\n",
    "        print(f\"\\nüßÆ Detailed Calculation:\")\n",
    "        for component, details in company_result['calculation_details'].items():\n",
    "            print(f\"   {component}:\")\n",
    "            print(f\"     Raw Score: {details.get('raw_score', 'N/A')}\")\n",
    "            print(f\"     Weight: {details.get('weight', 'N/A')}\")\n",
    "            print(f\"     Weighted Score: {details.get('weighted_score', 'N/A')}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    \n",
    "    if company_result['total_score'] < 60:\n",
    "        print(\"   - Low priority: Consider for future nurturing campaigns\")\n",
    "    elif company_result['total_score'] < 75:\n",
    "        print(\"   - Medium priority: Good for targeted marketing\")\n",
    "    elif company_result['total_score'] < 90:\n",
    "        print(\"   - High priority: Strong prospect for outreach\")\n",
    "    else:\n",
    "        print(\"   - Top priority: Immediate sales engagement recommended\")\n",
    "    \n",
    "    # Scoring improvement suggestions\n",
    "    lowest_component = min(company_result['component_scores'].items(), key=lambda x: x[1])\n",
    "    print(f\"   - Focus area: {lowest_component[0]} (score: {lowest_component[1]:.2f})\")\n",
    "    \n",
    "    return company_result\n",
    "\n",
    "# Analyze top and bottom companies\n",
    "if scoring_results:\n",
    "    # Sort by score\n",
    "    sorted_results = sorted(scoring_results, key=lambda x: x['total_score'], reverse=True)\n",
    "    \n",
    "    print(\"üèÜ TOP SCORING COMPANY:\")\n",
    "    top_company = analyze_company_scoring(sorted_results[0]['company_name'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    print(\"üìâ LOWEST SCORING COMPANY:\")\n",
    "    bottom_company = analyze_company_scoring(sorted_results[-1]['company_name'])\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No scoring results available for deep dive analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Custom Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis functions\n",
    "print(\"üõ†Ô∏è Custom Analysis Tools\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "def test_custom_weights(custom_weights):\n",
    "    \"\"\"Test scoring with custom weights\"\"\"\n",
    "    print(f\"\\nüß™ Testing custom weights: {custom_weights}\")\n",
    "    \n",
    "    custom_scores = []\n",
    "    for result in scoring_results:\n",
    "        component_scores = result['component_scores']\n",
    "        \n",
    "        weighted_score = sum(\n",
    "            component_scores.get(component, 0) * weight\n",
    "            for component, weight in custom_weights.items()\n",
    "        )\n",
    "        \n",
    "        custom_scores.append({\n",
    "            'company': result['company_name'],\n",
    "            'original_score': result['total_score'],\n",
    "            'custom_score': weighted_score,\n",
    "            'difference': weighted_score - result['total_score']\n",
    "        })\n",
    "    \n",
    "    # Sort by custom score\n",
    "    custom_scores.sort(key=lambda x: x['custom_score'], reverse=True)\n",
    "    \n",
    "    df_custom = pd.DataFrame(custom_scores)\n",
    "    display(df_custom)\n",
    "    \n",
    "    return df_custom\n",
    "\n",
    "def analyze_keyword_gaps():\n",
    "    \"\"\"Identify companies with low keyword matches\"\"\"\n",
    "    print(f\"\\nüîç Keyword Gap Analysis\")\n",
    "    \n",
    "    keyword_gaps = []\n",
    "    \n",
    "    for result in scoring_results:\n",
    "        total_keywords = sum(len(keywords) for keywords in result['keywords_found'].values())\n",
    "        \n",
    "        keyword_gaps.append({\n",
    "            'company': result['company_name'],\n",
    "            'total_score': result['total_score'],\n",
    "            'total_keywords': total_keywords,\n",
    "            'tech_score': result['component_scores'].get('technology_relevance', 0)\n",
    "        })\n",
    "    \n",
    "    df_gaps = pd.DataFrame(keyword_gaps)\n",
    "    df_gaps = df_gaps.sort_values('total_keywords')\n",
    "    \n",
    "    print(\"Companies with fewest keyword matches:\")\n",
    "    display(df_gaps.head())\n",
    "    \n",
    "    return df_gaps\n",
    "\n",
    "# Example usage\n",
    "print(\"üí° Available Tools:\")\n",
    "print(\"   - test_custom_weights(weights_dict)\")\n",
    "print(\"   - analyze_keyword_gaps()\")\n",
    "print(\"   - analyze_company_scoring(company_name)\")\n",
    "\n",
    "# Example: Test defense-heavy weighting\n",
    "if scoring_results:\n",
    "    print(\"\\nüß™ Example: Defense-Heavy Weighting\")\n",
    "    defense_heavy = {\n",
    "        'defense_contract_score': 0.6,\n",
    "        'technology_relevance': 0.2,\n",
    "        'compliance_indicators': 0.15,\n",
    "        'firmographics': 0.05\n",
    "    }\n",
    "    test_custom_weights(defense_heavy)\n",
    "    \n",
    "    print(\"\\nüîç Keyword Gap Analysis:\")\n",
    "    analyze_keyword_gaps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export analysis results\n",
    "print(\"üíæ Exporting Analysis Results\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "try:\n",
    "    # Create results directory\n",
    "    results_dir = Path(\"../data/research_results\")\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Export detailed scoring results\n",
    "    if 'df_results' in locals():\n",
    "        scoring_csv = results_dir / f\"scoring_analysis_{timestamp}.csv\"\n",
    "        df_results.to_csv(scoring_csv, index=False)\n",
    "        print(f\"‚úÖ Scoring results saved: {scoring_csv}\")\n",
    "    \n",
    "    # Export weight analysis\n",
    "    if 'scenario_results' in locals():\n",
    "        weight_analysis_file = results_dir / f\"weight_analysis_{timestamp}.json\"\n",
    "        weight_data = {\n",
    "            'scenarios': weight_scenarios,\n",
    "            'results': scenario_results,\n",
    "            'companies': company_names\n",
    "        }\n",
    "        with open(weight_analysis_file, 'w') as f:\n",
    "            json.dump(weight_data, f, indent=2)\n",
    "        print(f\"‚úÖ Weight analysis saved: {weight_analysis_file}\")\n",
    "    \n",
    "    # Export keyword analysis\n",
    "    if 'all_keywords_found' in locals():\n",
    "        keyword_file = results_dir / f\"keyword_analysis_{timestamp}.json\"\n",
    "        keyword_data = {\n",
    "            'keywords_by_category': all_keywords_found,\n",
    "            'keyword_company_mapping': keyword_company_mapping\n",
    "        }\n",
    "        with open(keyword_file, 'w') as f:\n",
    "            json.dump(keyword_data, f, indent=2)\n",
    "        print(f\"‚úÖ Keyword analysis saved: {keyword_file}\")\n",
    "    \n",
    "    # Create analysis summary\n",
    "    summary_file = results_dir / f\"scoring_analysis_summary_{timestamp}.txt\"\n",
    "    \n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"ATOMUS SCORING ANALYSIS SUMMARY\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        if scoring_results:\n",
    "            scores = [r['total_score'] for r in scoring_results]\n",
    "            f.write(f\"SCORE STATISTICS:\\n\")\n",
    "            f.write(f\"  Companies Analyzed: {len(scoring_results)}\\n\")\n",
    "            f.write(f\"  Mean Score: {np.mean(scores):.2f}\\n\")\n",
    "            f.write(f\"  Median Score: {np.median(scores):.2f}\\n\")\n",
    "            f.write(f\"  Score Range: {np.min(scores):.2f} - {np.max(scores):.2f}\\n\\n\")\n",
    "            \n",
    "            tiers = [r['tier_classification'] for r in scoring_results]\n",
    "            tier_counts = Counter(tiers)\n",
    "            f.write(f\"TIER DISTRIBUTION:\\n\")\n",
    "            for tier, count in tier_counts.items():\n",
    "                percentage = (count / len(tiers)) * 100\n",
    "                f.write(f\"  {tier}: {count} companies ({percentage:.1f}%)\\n\")\n",
    "        \n",
    "        f.write(f\"\\nCONFIGURATION USED:\\n\")\n",
    "        f.write(f\"  Weights: {config['weights']}\\n\")\n",
    "        f.write(f\"  Tier Thresholds: {config['tier_thresholds']}\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Analysis summary saved: {summary_file}\")\n",
    "    print(f\"\\nüìÅ All analysis files saved to: {results_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving analysis results: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Analysis Complete\n",
    "\n",
    "This notebook has provided comprehensive analysis of the Atomus scoring algorithm including:\n",
    "\n",
    "- ‚úÖ **Score Distribution Analysis** - Understanding how companies are scored\n",
    "- ‚úÖ **Keyword Effectiveness** - Which keywords are most valuable\n",
    "- ‚úÖ **Weight Sensitivity** - How weight changes affect rankings\n",
    "- ‚úÖ **Tier Optimization** - Optimal threshold configurations\n",
    "- ‚úÖ **Company Deep Dives** - Detailed individual analysis\n",
    "- ‚úÖ **Custom Analysis Tools** - Functions for ongoing optimization\n",
    "\n",
    "Use the insights from this analysis to refine your scoring algorithm and improve prospect identification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}